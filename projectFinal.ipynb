{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine, fetch_openml, fetch_20newsgroups, fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt # Added for plotting\n",
    "\n",
    "# 1. SVD Implementation from Scratch\n",
    "def svd_from_scratch(A):\n",
    "    with tqdm(total=3, desc=\"SVD Computation (Scratch)\") as pbar:\n",
    "        ATA = np.dot(A.T, A)\n",
    "        AAT = np.dot(A, A.T)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        eigvals_V, V = np.linalg.eigh(ATA)\n",
    "        eigvals_U, U = np.linalg.eigh(AAT)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        idx_V = eigvals_V.argsort()[::-1]\n",
    "        eigvals_V = eigvals_V[idx_V]\n",
    "        V = V[:, idx_V]\n",
    "        \n",
    "        idx_U = eigvals_U.argsort()[::-1]\n",
    "        eigvals_U = eigvals_U[idx_U]\n",
    "        U = U[:, idx_U]\n",
    "        \n",
    "        singular_values = np.sqrt(np.abs(eigvals_V))\n",
    "        singular_values = np.sort(singular_values)[::-1]\n",
    "        \n",
    "        diag_len = min(A.shape[0], A.shape[1])\n",
    "        Sigma_diag = singular_values[:diag_len] # 1D array of singular values\n",
    "\n",
    "        U_final = U[:, :diag_len]\n",
    "        Vt_final = V.T[:diag_len, :] # This Vt needs to be constructed carefully\n",
    "                                     # V are eigenvectors of A.T @ A. V.T needs to be (k, n_features)\n",
    "                                     # V from eigh(ATA) is (n_features, n_features)\n",
    "                                     # Vt_final should be V.T (all rows of V.T, truncated to diag_len columns if M < N)\n",
    "                                     # Or rather, Vt are the first 'diag_len' rows of the full V.T\n",
    "        # A more standard way:\n",
    "        # V comes from ATA. The columns of V are the right singular vectors.\n",
    "        # Vt = V.T\n",
    "        # singular_values are sqrt of eigenvalues of ATA (or AAT)\n",
    "        \n",
    "        # For the purpose of this function returning U, S_1D, Vt\n",
    "        # Let S_1D be the sorted singular values.\n",
    "        # U should be the corresponding left singular vectors\n",
    "        # Vt should be the corresponding right singular vectors (transposed)\n",
    "        pbar.update(1)\n",
    "    # This scratch SVD is complex to get perfectly aligned with np.linalg.svd especially for non-square A\n",
    "    # For now, we return what's calculated, but np.linalg.svd is used for most critical parts.\n",
    "    # The crucial part is Vt for the transformation matrix.\n",
    "    return U_final, Sigma_diag, V.T # V.T from eigh(ATA) is the correct Vt\n",
    "\n",
    "# 2. EVD Implementation from Scratch (for covariance matrix)\n",
    "def evd_from_scratch(A):\n",
    "    with tqdm(total=2, desc=\"EVD Computation\") as pbar:\n",
    "        cov_matrix = np.cov(A.T)\n",
    "        pbar.update(1)\n",
    "        eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n",
    "        idx = eigvals.argsort()[::-1]\n",
    "        eigvals = eigvals[idx]\n",
    "        eigvecs = eigvecs[:, idx]\n",
    "        pbar.update(1)\n",
    "    return eigvals, eigvecs\n",
    "\n",
    "# 3. Get Transformation Matrices with Variance Retention\n",
    "def get_svd_transform_matrix(X, variance_retained=0.95, use_linalg_svd=False):\n",
    "    singular_values = None\n",
    "    Vt = None\n",
    "    if use_linalg_svd:\n",
    "        with tqdm(total=1, desc=\"SVD Computation (linalg.svd)\") as pbar:\n",
    "            try:\n",
    "                U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "                singular_values = s\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                print(f\"SVD computation failed: {e}. Skipping SVD for this dataset.\")\n",
    "                return None\n",
    "            pbar.update(1)\n",
    "    else:\n",
    "        U_scratch, s_scratch, Vt_scratch = svd_from_scratch(X) # s_scratch is 1D\n",
    "        singular_values = s_scratch\n",
    "        Vt = Vt_scratch\n",
    "    \n",
    "    if singular_values is None or Vt is None:\n",
    "        print(\"SVD: Singular values or Vt not computed.\")\n",
    "        return None\n",
    "\n",
    "    variance_explained = singular_values**2 / np.sum(singular_values**2)\n",
    "    cumulative_variance = np.cumsum(variance_explained)\n",
    "    \n",
    "    k_candidates = np.where(cumulative_variance >= variance_retained)[0]\n",
    "    if len(k_candidates) == 0:\n",
    "        k = len(singular_values)\n",
    "    else:\n",
    "        k = k_candidates[0] + 1\n",
    "    \n",
    "    transform_matrix = Vt.T[:, :k]\n",
    "    \n",
    "    actual_variance_retained = cumulative_variance[k-1] if k > 0 and k <= len(cumulative_variance) else (cumulative_variance[-1] if len(cumulative_variance) > 0 else 0.0)\n",
    "    print(f\"SVD: Selected {k} components retaining {actual_variance_retained:.4f} variance.\")\n",
    "    return transform_matrix\n",
    "\n",
    "def get_evd_transform_matrix(X, variance_retained=0.95):\n",
    "    eigvals, eigvecs = evd_from_scratch(X)\n",
    "    total_variance = np.sum(eigvals)\n",
    "    if total_variance == 0:\n",
    "        print(\"EVD: Total variance is zero. Cannot determine components.\")\n",
    "        return eigvecs[:, :min(1, eigvecs.shape[1])] # return at least one component or empty if no eigvecs\n",
    "\n",
    "    cumulative_variance = np.cumsum(eigvals) / total_variance\n",
    "    k_candidates = np.where(cumulative_variance >= variance_retained)[0]\n",
    "    if len(k_candidates) == 0:\n",
    "        k = len(eigvals)\n",
    "    else:\n",
    "        k = k_candidates[0] + 1\n",
    "            \n",
    "    transform_matrix = eigvecs[:, :k]\n",
    "    actual_variance_retained = cumulative_variance[k-1] if k > 0 and k <= len(cumulative_variance) else (cumulative_variance[-1] if len(cumulative_variance) > 0 else 0.0)\n",
    "    print(f\"EVD: Selected {k} components retaining {actual_variance_retained:.4f} variance.\")\n",
    "    return transform_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load and Preprocess Datasets\n",
    "def load_and_preprocess_data():\n",
    "    print(\"Loading and Preprocessing Sensorless, Wine, MNIST Datasets...\")\n",
    "    X_sensor_train, X_sensor_test, y_sensor_train, y_sensor_test = None, None, None, None\n",
    "    X_wine_train, X_wine_test, y_wine_train, y_wine_test = None, None, None, None\n",
    "    X_mnist_train, X_mnist_test, y_mnist_train_all, y_mnist_test_labels = None, None, None, None # Renamed y_mnist_test\n",
    "\n",
    "    with tqdm(total=6, desc=\"Data Preprocessing (S/W/M)\") as pbar:\n",
    "        try:\n",
    "            data = np.loadtxt(\"Sensorless_drive_diagnosis.txt\", delimiter=' ')\n",
    "            X_sensor = data[:, :-1]\n",
    "            y_sensor = data[:, -1] - 1\n",
    "            scaler_sensor = StandardScaler()\n",
    "            X_sensor = scaler_sensor.fit_transform(X_sensor)\n",
    "            X_sensor_train, X_sensor_test, y_sensor_train, y_sensor_test = train_test_split(\n",
    "                X_sensor, y_sensor, test_size=0.2, random_state=42, stratify=y_sensor)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Sensorless_drive_diagnosis.txt not found. Skipping Sensorless dataset.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Sensorless dataset: {e}. Skipping.\")\n",
    "        pbar.update(1)\n",
    "        \n",
    "        try:\n",
    "            wine = load_wine()\n",
    "            X_wine = wine.data\n",
    "            y_wine = wine.target\n",
    "            scaler_wine = StandardScaler()\n",
    "            X_wine = scaler_wine.fit_transform(X_wine)\n",
    "            X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(\n",
    "                X_wine, y_wine, test_size=0.2, random_state=42, stratify=y_wine)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Wine dataset: {e}. Skipping.\")\n",
    "        pbar.update(1)\n",
    "        \n",
    "        try:\n",
    "            mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "            X_mnist = mnist.data\n",
    "            y_mnist = mnist.target.astype(int)\n",
    "            X_mnist_train_all_samples = X_mnist[:60000]\n",
    "            y_mnist_train_all = y_mnist[:60000] # y_mnist_train_all for training\n",
    "            X_mnist_test_samples = X_mnist[60000:]\n",
    "            y_mnist_test_labels = y_mnist[60000:] # y_mnist_test_labels for ground truth\n",
    "            \n",
    "            scaler_mnist = StandardScaler()\n",
    "            X_mnist_train = scaler_mnist.fit_transform(X_mnist_train_all_samples)\n",
    "            X_mnist_test = scaler_mnist.transform(X_mnist_test_samples) # X_mnist_test for model input\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load MNIST: {e}. Skipping MNIST dataset.\")\n",
    "        pbar.update(4)\n",
    "    \n",
    "    return (X_sensor_train, X_sensor_test, y_sensor_train, y_sensor_test), \\\n",
    "           (X_wine_train, X_wine_test, y_wine_train, y_wine_test), \\\n",
    "           (X_mnist_train, X_mnist_test, y_mnist_train_all, y_mnist_test_labels)\n",
    "\n",
    "def load_and_preprocess_newsgroups():\n",
    "    try:\n",
    "        print(\"Loading and Preprocessing 20 Newsgroups Dataset...\")\n",
    "        with tqdm(total=3, desc=\"Newsgroups Preprocessing\") as pbar:\n",
    "            newsgroups_train_data = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
    "            newsgroups_test_data = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
    "            pbar.update(1)\n",
    "            vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "            X_news_train = vectorizer.fit_transform(newsgroups_train_data.data).toarray()\n",
    "            y_news_train = newsgroups_train_data.target\n",
    "            pbar.update(1)\n",
    "            X_news_test = vectorizer.transform(newsgroups_test_data.data).toarray()\n",
    "            y_news_test = newsgroups_test_data.target\n",
    "            pbar.update(1)\n",
    "        return X_news_train, X_news_test, y_news_train, y_news_test\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load 20 Newsgroups: {e}. Skipping Newsgroups dataset.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def load_and_preprocess_covtype(test_size=0.2, random_state=42):\n",
    "    try:\n",
    "        print(\"Loading and Preprocessing Covertype Dataset...\")\n",
    "        with tqdm(total=4, desc=\"Covertype Preprocessing\") as pbar:\n",
    "            covtype = fetch_covtype()\n",
    "            X = covtype.data\n",
    "            y = covtype.target - 1\n",
    "            pbar.update(1)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "            pbar.update(1)\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            pbar.update(1)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            pbar.update(1)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load Covertype: {e}. Skipping Covertype dataset.\")\n",
    "        return None, None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train and Evaluate KNN\n",
    "def train_knn(X_train, X_test, y_train, y_test, label):\n",
    "    if X_train is None or y_train is None or X_train.shape[0] == 0:\n",
    "        print(f\"Skipping KNN for {label} due to missing/empty training data.\")\n",
    "        return 0.0\n",
    "    if X_test is None or y_test is None or X_test.shape[0] == 0 :\n",
    "        print(f\"Skipping KNN for {label} due to missing/empty test data.\")\n",
    "        # Can't compute accuracy, but model could still be trained.\n",
    "        # For this script's purpose, if test data is missing, skip.\n",
    "        return 0.0\n",
    "        \n",
    "    knn = KNeighborsClassifier(n_neighbors=min(5, X_train.shape[0]))\n",
    "    with tqdm(total=2, desc=f\"KNN Training ({label})\") as pbar:\n",
    "        start_time = time.time()\n",
    "        knn.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        pbar.update(1)\n",
    "        accuracy = 0.0\n",
    "        inference_time = 0.0\n",
    "        if X_test is not None and y_test is not None and X_test.shape[0] > 0:\n",
    "             start_time = time.time()\n",
    "             accuracy = knn.score(X_test, y_test)\n",
    "             inference_time = time.time() - start_time\n",
    "        pbar.update(1)\n",
    "    \n",
    "    print(f\"{label} - Features: {X_train.shape[1]}, Accuracy: {accuracy:.4f}, \"\n",
    "          f\"Training Time: {train_time:.2f}s, Inference Time: {inference_time:.2f}s\")\n",
    "    return accuracy # Model itself isn't returned here, but could be if needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Neural Network Definition (PyTorch)\n",
    "class ClassifierNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ClassifierNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 7. Train and Evaluate Neural Network (MODIFIED TO RETURN MODEL)\n",
    "def train_neural_network(X_train, X_test, y_train, y_test, label, output_dim, epochs=10):\n",
    "    if X_train is None or y_train is None or X_train.shape[0] == 0 or X_train.shape[1] == 0:\n",
    "        print(f\"Skipping NN for {label} due to missing/empty/zero-feature training data.\")\n",
    "        return None, 0.0\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    y_train_tensor = torch.LongTensor(y_train)\n",
    "    \n",
    "    batch_size = 32 if X_train.shape[0] < 100000 else 128 \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = ClassifierNet(input_dim=X_train.shape[1], output_dim=output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs), desc=f\"NN Training ({label}) - E{epochs} B{batch_size}\"):\n",
    "        for data, target_batch in train_loader: # Renamed target to target_batch\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    inference_time = 0.0\n",
    "    if X_test is not None and y_test is not None and X_test.shape[0] > 0:\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        y_test_tensor = torch.LongTensor(y_test)\n",
    "        model.eval()\n",
    "        with tqdm(total=1, desc=f\"NN Evaluation ({label})\") as pbar:\n",
    "            eval_start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                if X_test_tensor.shape[0] > 20000:\n",
    "                    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "                    correct_preds, total_preds = 0, 0\n",
    "                    for data, target_batch in test_loader: # Renamed target to target_batch\n",
    "                        output = model(data)\n",
    "                        _, predicted = torch.max(output, 1)\n",
    "                        correct_preds += (predicted == target_batch).sum().item()\n",
    "                        total_preds += target_batch.size(0)\n",
    "                    if total_preds > 0: accuracy = correct_preds / total_preds\n",
    "                else:\n",
    "                    output = model(X_test_tensor)\n",
    "                    _, predicted = torch.max(output, 1)\n",
    "                    accuracy = (predicted == y_test_tensor).float().mean().item()\n",
    "            inference_time = time.time() - eval_start_time\n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(f\"{label} - Features: {X_train.shape[1]}, Accuracy: {accuracy:.4f}, \"\n",
    "          f\"Training Time: {train_time:.2f}s, Inference Time: {inference_time:.2f}s\")\n",
    "    return model, accuracy # Return the trained model and accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Function to show MNIST predictions (NEW)\n",
    "def show_mnist_predictions(images_scaled, true_labels, model_orig, model_svd, model_evd, V_svd_transform, eigvecs_evd_transform, num_images=6):\n",
    "    if images_scaled is None or true_labels is None or \\\n",
    "       model_orig is None or model_svd is None or model_evd is None or \\\n",
    "       V_svd_transform is None or eigvecs_evd_transform is None:\n",
    "        print(\"Cannot show MNIST predictions due to missing components.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nDisplaying MNIST Predictions...\")\n",
    "    \n",
    "    # Select a few images\n",
    "    sample_indices = np.random.choice(images_scaled.shape[0], num_images, replace=False)\n",
    "    sample_images_scaled = images_scaled[sample_indices]\n",
    "    sample_labels = true_labels[sample_indices]\n",
    "\n",
    "    fig, axes = plt.subplots(2, (num_images + 1) // 2, figsize=(12, 7))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    model_orig.eval()\n",
    "    model_svd.eval()\n",
    "    model_evd.eval()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        if i >= len(axes): break # Should not happen with current setup\n",
    "\n",
    "        img_scaled = sample_images_scaled[i] # This is scaled and 1D (784,)\n",
    "        \n",
    "        # For display, reshape (original MNIST images are 28x28)\n",
    "        # The scaler alters the range, but cmap='gray' will work.\n",
    "        display_img = img_scaled.reshape(28, 28)\n",
    "        \n",
    "        # Predictions\n",
    "        pred_orig, pred_svd, pred_evd = \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Original model\n",
    "            img_tensor_orig = torch.FloatTensor(img_scaled).unsqueeze(0)\n",
    "            output_orig = model_orig(img_tensor_orig)\n",
    "            pred_orig = torch.max(output_orig, 1)[1].item()\n",
    "\n",
    "            # SVD model\n",
    "            if V_svd_transform is not None:\n",
    "                img_svd = img_scaled @ V_svd_transform\n",
    "                img_tensor_svd = torch.FloatTensor(img_svd).unsqueeze(0)\n",
    "                if img_tensor_svd.shape[1] == model_svd.fc1.in_features: # Check feature compatibility\n",
    "                    output_svd = model_svd(img_tensor_svd)\n",
    "                    pred_svd = torch.max(output_svd, 1)[1].item()\n",
    "                else:\n",
    "                    pred_svd = \"Dim mismatch\"\n",
    "\n",
    "\n",
    "            # EVD model\n",
    "            if eigvecs_evd_transform is not None:\n",
    "                img_evd = img_scaled @ eigvecs_evd_transform\n",
    "                img_tensor_evd = torch.FloatTensor(img_evd).unsqueeze(0)\n",
    "                if img_tensor_evd.shape[1] == model_evd.fc1.in_features: # Check feature compatibility\n",
    "                    output_evd = model_evd(img_tensor_evd)\n",
    "                    pred_evd = torch.max(output_evd, 1)[1].item()\n",
    "                else:\n",
    "                    pred_evd = \"Dim mismatch\"\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.imshow(display_img, cmap='gray')\n",
    "        ax.set_title(f\"True: {sample_labels[i]}\\nOrig: {pred_orig}, SVD: {pred_svd}, EVD: {pred_evd}\", fontsize=9)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Preprocessing Sensorless, Wine, MNIST Datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Preprocessing (S/W/M): 100%|██████████| 6/6 [00:02<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Preprocessing 20 Newsgroups Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Newsgroups Preprocessing: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Preprocessing Covertype Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Covertype Preprocessing: 100%|██████████| 4/4 [00:00<00:00,  6.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# 9. Main Execution (MODIFIED TO STORE MNIST MODELS AND CALL PLOTTING)\n",
    "\n",
    "# Load datasets\n",
    "(X_sensor_train, X_sensor_test, y_sensor_train, y_sensor_test), \\\n",
    "(X_wine_train, X_wine_test, y_wine_train, y_wine_test), \\\n",
    "(X_mnist_train, X_mnist_test_scaled, y_mnist_train, y_mnist_test_true_labels) = load_and_preprocess_data() # X_mnist_test is scaled\n",
    "\n",
    "X_news_train, X_news_test, y_news_train, y_news_test = load_and_preprocess_newsgroups()\n",
    "X_cov_train, X_cov_test, y_cov_train, y_cov_test = load_and_preprocess_covtype()\n",
    "\n",
    "# --- Storage for MNIST specific models and transforms ---\n",
    "mnist_components = {\n",
    "    \"model_orig\": None, \"model_svd\": None, \"model_evd\": None,\n",
    "    \"V_svd_transform\": None, \"eigvecs_evd_transform\": None,\n",
    "    \"X_test_scaled\": X_mnist_test_scaled, # Scaled test features\n",
    "    \"y_test_true\": y_mnist_test_true_labels   # True labels for test set\n",
    "}\n",
    "\n",
    "datasets_for_nn = []\n",
    "if X_sensor_train is not None:\n",
    "    datasets_for_nn.append({\n",
    "        \"name\": \"Sensorless\", \"X_train\": X_sensor_train, \"X_test\": X_sensor_test, \n",
    "        \"y_train\": y_sensor_train, \"y_test\": y_sensor_test, \"output_dim\": 11, \"use_linalg_svd\": True\n",
    "    })\n",
    "if X_mnist_train is not None: # Check if MNIST data loaded\n",
    "    datasets_for_nn.append({\n",
    "        \"name\": \"MNIST\", \"X_train\": X_mnist_train, \"X_test\": X_mnist_test_scaled, # Use scaled test data\n",
    "        \"y_train\": y_mnist_train, \"y_test\": y_mnist_test_true_labels, \"output_dim\": 10, \"use_linalg_svd\": True\n",
    "    })\n",
    "if X_news_train is not None:\n",
    "        datasets_for_nn.append({\n",
    "        \"name\": \"Newsgroups\", \"X_train\": X_news_train, \"X_test\": X_news_test,\n",
    "        \"y_train\": y_news_train, \"y_test\": y_news_test, \"output_dim\": 20, \"use_linalg_svd\": True\n",
    "    })\n",
    "if X_cov_train is not None:\n",
    "    datasets_for_nn.append({\n",
    "        \"name\": \"Covertype\", \"X_train\": X_cov_train, \"X_test\": X_cov_test,\n",
    "        \"y_train\": y_cov_train, \"y_test\": y_cov_test, \"output_dim\": 7, \"use_linalg_svd\": True\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wine Original Features: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (Scratch): 100%|██████████| 3/3 [00:00<00:00, 599.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 10 components retaining 0.9629 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00, 3695.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 10 components retaining 0.9629 variance.\n",
      "Wine SVD Reduced Features: 10\n",
      "Wine EVD Reduced Features: 10\n",
      "\n",
      "KNN Results on Wine Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN Training (Original Data (Wine)): 100%|██████████| 2/2 [00:00<00:00, 273.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Wine) - Features: 13, Accuracy: 0.9722, Training Time: 0.00s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN Training (SVD Reduced Data (Wine)): 100%|██████████| 2/2 [00:00<00:00, 564.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Wine) - Features: 10, Accuracy: 0.9722, Training Time: 0.00s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN Training (EVD Reduced Data (Wine)): 100%|██████████| 2/2 [00:00<00:00, 344.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Wine) - Features: 10, Accuracy: 0.9722, Training Time: 0.00s, Inference Time: 0.00s\n",
      "\n",
      "Sensorless Original Features: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:00<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 21 components retaining 0.9575 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00, 202.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 21 components retaining 0.9575 variance.\n",
      "Sensorless SVD Reduced Features: 21\n",
      "Sensorless EVD Reduced Features: 21\n",
      "\n",
      "Neural Network Results on Sensorless Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (Sensorless)) - E10 B32: 100%|██████████| 10/10 [00:08<00:00,  1.21it/s]\n",
      "NN Evaluation (Original Data (Sensorless)): 100%|██████████| 1/1 [00:00<00:00, 245.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Sensorless) - Features: 48, Accuracy: 0.9900, Training Time: 8.23s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (Sensorless)) - E10 B32: 100%|██████████| 10/10 [00:07<00:00,  1.26it/s]\n",
      "NN Evaluation (SVD Reduced Data (Sensorless)): 100%|██████████| 1/1 [00:00<00:00, 291.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Sensorless) - Features: 21, Accuracy: 0.9807, Training Time: 7.92s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (Sensorless)) - E10 B32: 100%|██████████| 10/10 [00:08<00:00,  1.18it/s]\n",
      "NN Evaluation (EVD Reduced Data (Sensorless)): 100%|██████████| 1/1 [00:00<00:00, 274.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Sensorless) - Features: 21, Accuracy: 0.9836, Training Time: 8.47s, Inference Time: 0.00s\n",
      "\n",
      "MNIST Original Features: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:11<00:00, 11.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 331 components retaining 0.9503 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 331 components retaining 0.9503 variance.\n",
      "MNIST SVD Reduced Features: 331\n",
      "MNIST EVD Reduced Features: 331\n",
      "\n",
      "Neural Network Results on MNIST Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (MNIST)) - E10 B32: 100%|██████████| 10/10 [00:27<00:00,  2.78s/it]\n",
      "NN Evaluation (Original Data (MNIST)): 100%|██████████| 1/1 [00:00<00:00, 68.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (MNIST) - Features: 784, Accuracy: 0.9770, Training Time: 27.82s, Inference Time: 0.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (MNIST)) - E10 B32: 100%|██████████| 10/10 [00:18<00:00,  1.81s/it]\n",
      "NN Evaluation (SVD Reduced Data (MNIST)): 100%|██████████| 1/1 [00:00<00:00, 193.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (MNIST) - Features: 331, Accuracy: 0.9706, Training Time: 18.14s, Inference Time: 0.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (MNIST)) - E10 B32: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
      "NN Evaluation (EVD Reduced Data (MNIST)): 100%|██████████| 1/1 [00:00<00:00, 205.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (MNIST) - Features: 331, Accuracy: 0.9746, Training Time: 15.31s, Inference Time: 0.00s\n",
      "\n",
      "Newsgroups Original Features: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [02:08<00:00, 128.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 3172 components retaining 0.9500 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:32<00:00, 16.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 3183 components retaining 0.9500 variance.\n",
      "Newsgroups SVD Reduced Features: 3172\n",
      "Newsgroups EVD Reduced Features: 3183\n",
      "\n",
      "Neural Network Results on Newsgroups Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (Newsgroups)) - E10 B32: 100%|██████████| 10/10 [00:08<00:00,  1.20it/s]\n",
      "NN Evaluation (Original Data (Newsgroups)): 100%|██████████| 1/1 [00:00<00:00, 36.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Newsgroups) - Features: 5000, Accuracy: 0.5901, Training Time: 8.38s, Inference Time: 0.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (Newsgroups)) - E10 B32: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]\n",
      "NN Evaluation (SVD Reduced Data (Newsgroups)): 100%|██████████| 1/1 [00:00<00:00, 53.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Newsgroups) - Features: 3172, Accuracy: 0.5514, Training Time: 5.94s, Inference Time: 0.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (Newsgroups)) - E10 B32: 100%|██████████| 10/10 [00:05<00:00,  1.78it/s]\n",
      "NN Evaluation (EVD Reduced Data (Newsgroups)): 100%|██████████| 1/1 [00:00<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Newsgroups) - Features: 3183, Accuracy: 0.5543, Training Time: 5.63s, Inference Time: 0.02s\n",
      "\n",
      "Covertype Original Features: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 43 components retaining 0.9505 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 43 components retaining 0.9505 variance.\n",
      "Covertype SVD Reduced Features: 43\n",
      "Covertype EVD Reduced Features: 43\n",
      "\n",
      "Neural Network Results on Covertype Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (Covertype)) - E10 B128: 100%|██████████| 10/10 [00:36<00:00,  3.65s/it]\n",
      "NN Evaluation (Original Data (Covertype)): 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Covertype) - Features: 54, Accuracy: 0.8661, Training Time: 36.50s, Inference Time: 0.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (Covertype)) - E10 B128: 100%|██████████| 10/10 [00:35<00:00,  3.54s/it]\n",
      "NN Evaluation (SVD Reduced Data (Covertype)): 100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Covertype) - Features: 43, Accuracy: 0.8310, Training Time: 35.37s, Inference Time: 0.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (Covertype)) - E10 B128: 100%|██████████| 10/10 [00:36<00:00,  3.69s/it]\n",
      "NN Evaluation (EVD Reduced Data (Covertype)): 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Covertype) - Features: 43, Accuracy: 0.8327, Training Time: 36.89s, Inference Time: 0.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if X_wine_train is not None:\n",
    "    print(f\"\\nWine Original Features: {X_wine_train.shape[1]}\")\n",
    "    V_wine_svd = get_svd_transform_matrix(X_wine_train, 0.95, use_linalg_svd=False)\n",
    "    eigvecs_wine_evd = get_evd_transform_matrix(X_wine_train, 0.95)\n",
    "    \n",
    "    X_wine_train_svd, X_wine_test_svd = (X_wine_train @ V_wine_svd, X_wine_test @ V_wine_svd) if V_wine_svd is not None else (None, None)\n",
    "    X_wine_train_evd, X_wine_test_evd = (X_wine_train @ eigvecs_wine_evd, X_wine_test @ eigvecs_wine_evd) if eigvecs_wine_evd is not None else (None, None)\n",
    "    if X_wine_train_svd is not None: print(f\"Wine SVD Reduced Features: {X_wine_train_svd.shape[1]}\")\n",
    "    if X_wine_train_evd is not None: print(f\"Wine EVD Reduced Features: {X_wine_train_evd.shape[1]}\")\n",
    "\n",
    "    print(\"\\nKNN Results on Wine Dataset:\")\n",
    "    train_knn(X_wine_train, X_wine_test, y_wine_train, y_wine_test, \"Original Data (Wine)\")\n",
    "    train_knn(X_wine_train_svd, X_wine_test_svd, y_wine_train, y_wine_test, \"SVD Reduced Data (Wine)\")\n",
    "    train_knn(X_wine_train_evd, X_wine_test_evd, y_wine_train, y_wine_test, \"EVD Reduced Data (Wine)\")\n",
    "\n",
    "for ds in datasets_for_nn:\n",
    "    name = ds[\"name\"]\n",
    "    X_train, X_test, y_train, y_test = ds[\"X_train\"], ds[\"X_test\"], ds[\"y_train\"], ds[\"y_test\"]\n",
    "    output_dim = ds[\"output_dim\"]\n",
    "    use_linalg = ds.get(\"use_linalg_svd\", True)\n",
    "\n",
    "    print(f\"\\n{name} Original Features: {X_train.shape[1]}\")\n",
    "    \n",
    "    V_svd, eigvecs_evd = None, None # Initialize\n",
    "    if X_train.shape[0] > 0 and X_train.shape[1] > 0 : # Ensure data is not empty for SVD/EVD\n",
    "        V_svd = get_svd_transform_matrix(X_train, 0.95, use_linalg_svd=use_linalg)\n",
    "        eigvecs_evd = get_evd_transform_matrix(X_train, 0.95)\n",
    "    \n",
    "        if name == \"MNIST\": # Store MNIST transformation matrices\n",
    "            mnist_components[\"V_svd_transform\"] = V_svd\n",
    "            mnist_components[\"eigvecs_evd_transform\"] = eigvecs_evd\n",
    "    else:\n",
    "        print(f\"Skipping SVD/EVD for {name} due to empty or zero-feature training data.\")\n",
    "\n",
    "\n",
    "    X_train_svd, X_test_svd = (X_train @ V_svd, X_test @ V_svd) if V_svd is not None and X_test is not None else (None, None)\n",
    "    X_train_evd, X_test_evd = (X_train @ eigvecs_evd, X_test @ eigvecs_evd) if eigvecs_evd is not None and X_test is not None else (None, None)\n",
    "    \n",
    "    if X_train_svd is not None: print(f\"{name} SVD Reduced Features: {X_train_svd.shape[1]}\")\n",
    "    if X_train_evd is not None: print(f\"{name} EVD Reduced Features: {X_train_evd.shape[1]}\")\n",
    "        \n",
    "    print(f\"\\nNeural Network Results on {name} Dataset:\")\n",
    "    model_orig, acc_orig = train_neural_network(X_train, X_test, y_train, y_test, f\"Original Data ({name})\", output_dim)\n",
    "    model_svd, acc_svd = train_neural_network(X_train_svd, X_test_svd, y_train, y_test, f\"SVD Reduced Data ({name})\", output_dim)\n",
    "    model_evd, acc_evd = train_neural_network(X_train_evd, X_test_evd, y_train, y_test, f\"EVD Reduced Data ({name})\", output_dim)\n",
    "\n",
    "    if name == \"MNIST\": # Store trained MNIST models\n",
    "        mnist_components[\"model_orig\"] = model_orig\n",
    "        mnist_components[\"model_svd\"] = model_svd\n",
    "        mnist_components[\"model_evd\"] = model_evd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 85% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wine Original Features: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (Scratch): 100%|██████████| 3/3 [00:00<00:00, 433.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 10 components retaining 0.9629 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00, 5050.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 10 components retaining 0.9629 variance.\n",
      "Wine SVD Reduced Features: 10\n",
      "Wine EVD Reduced Features: 10\n",
      "\n",
      "KNN Results on Wine Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN Training (Original Data (Wine)): 100%|██████████| 2/2 [00:00<00:00, 561.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Wine) - Features: 13, Accuracy: 0.9722, Training Time: 0.00s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN Training (SVD Reduced Data (Wine)): 100%|██████████| 2/2 [00:00<00:00, 309.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Wine) - Features: 10, Accuracy: 0.9722, Training Time: 0.00s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KNN Training (EVD Reduced Data (Wine)): 100%|██████████| 2/2 [00:00<00:00, 512.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Wine) - Features: 10, Accuracy: 0.9722, Training Time: 0.00s, Inference Time: 0.00s\n",
      "\n",
      "Sensorless Original Features: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:00<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 14 components retaining 0.8656 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00, 219.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 14 components retaining 0.8656 variance.\n",
      "Sensorless SVD Reduced Features: 14\n",
      "Sensorless EVD Reduced Features: 14\n",
      "\n",
      "Neural Network Results on Sensorless Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "NN Training (Original Data (Sensorless)) - E10 B32: 100%|██████████| 10/10 [00:04<00:00,  2.28it/s]\n",
      "NN Evaluation (Original Data (Sensorless)): 100%|██████████| 1/1 [00:00<00:00, 361.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Sensorless) - Features: 48, Accuracy: 0.9874, Training Time: 4.39s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (Sensorless)) - E10 B32: 100%|██████████| 10/10 [00:04<00:00,  2.36it/s]\n",
      "NN Evaluation (SVD Reduced Data (Sensorless)): 100%|██████████| 1/1 [00:00<00:00, 382.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Sensorless) - Features: 14, Accuracy: 0.9100, Training Time: 4.23s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (Sensorless)) - E10 B32: 100%|██████████| 10/10 [00:04<00:00,  2.31it/s]\n",
      "NN Evaluation (EVD Reduced Data (Sensorless)): 100%|██████████| 1/1 [00:00<00:00, 80.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Sensorless) - Features: 14, Accuracy: 0.9033, Training Time: 4.34s, Inference Time: 0.01s\n",
      "\n",
      "MNIST Original Features: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 185 components retaining 0.8504 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 185 components retaining 0.8504 variance.\n",
      "MNIST SVD Reduced Features: 185\n",
      "MNIST EVD Reduced Features: 185\n",
      "\n",
      "Neural Network Results on MNIST Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (MNIST)) - E10 B32: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n",
      "NN Evaluation (Original Data (MNIST)): 100%|██████████| 1/1 [00:00<00:00, 202.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (MNIST) - Features: 784, Accuracy: 0.9745, Training Time: 9.77s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (MNIST)) - E10 B32: 100%|██████████| 10/10 [00:06<00:00,  1.47it/s]\n",
      "NN Evaluation (SVD Reduced Data (MNIST)): 100%|██████████| 1/1 [00:00<00:00, 381.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (MNIST) - Features: 185, Accuracy: 0.9720, Training Time: 6.82s, Inference Time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (MNIST)) - E10 B32: 100%|██████████| 10/10 [00:06<00:00,  1.49it/s]\n",
      "NN Evaluation (EVD Reduced Data (MNIST)): 100%|██████████| 1/1 [00:00<00:00, 343.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (MNIST) - Features: 185, Accuracy: 0.9690, Training Time: 6.72s, Inference Time: 0.00s\n",
      "\n",
      "Newsgroups Original Features: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:43<00:00, 43.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 2121 components retaining 0.8500 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:11<00:00,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 2136 components retaining 0.8501 variance.\n",
      "Newsgroups SVD Reduced Features: 2121\n",
      "Newsgroups EVD Reduced Features: 2136\n",
      "\n",
      "Neural Network Results on Newsgroups Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (Newsgroups)) - E10 B32: 100%|██████████| 10/10 [00:04<00:00,  2.23it/s]\n",
      "NN Evaluation (Original Data (Newsgroups)): 100%|██████████| 1/1 [00:00<00:00, 57.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Newsgroups) - Features: 5000, Accuracy: 0.5817, Training Time: 4.49s, Inference Time: 0.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (Newsgroups)) - E10 B32: 100%|██████████| 10/10 [00:02<00:00,  4.21it/s]\n",
      "NN Evaluation (SVD Reduced Data (Newsgroups)): 100%|██████████| 1/1 [00:00<00:00, 148.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Newsgroups) - Features: 2121, Accuracy: 0.5672, Training Time: 2.38s, Inference Time: 0.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (Newsgroups)) - E10 B32: 100%|██████████| 10/10 [00:02<00:00,  4.51it/s]\n",
      "NN Evaluation (EVD Reduced Data (Newsgroups)): 100%|██████████| 1/1 [00:00<00:00, 145.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Newsgroups) - Features: 2136, Accuracy: 0.5666, Training Time: 2.22s, Inference Time: 0.01s\n",
      "\n",
      "Covertype Original Features: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SVD Computation (linalg.svd): 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD: Selected 37 components retaining 0.8532 variance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVD Computation: 100%|██████████| 2/2 [00:00<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD: Selected 37 components retaining 0.8532 variance.\n",
      "Covertype SVD Reduced Features: 37\n",
      "Covertype EVD Reduced Features: 37\n",
      "\n",
      "Neural Network Results on Covertype Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (Original Data (Covertype)) - E10 B128: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it]\n",
      "NN Evaluation (Original Data (Covertype)): 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (Covertype) - Features: 54, Accuracy: 0.8743, Training Time: 22.52s, Inference Time: 0.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (SVD Reduced Data (Covertype)) - E10 B128: 100%|██████████| 10/10 [00:21<00:00,  2.14s/it]\n",
      "NN Evaluation (SVD Reduced Data (Covertype)): 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Reduced Data (Covertype) - Features: 37, Accuracy: 0.8242, Training Time: 21.39s, Inference Time: 0.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN Training (EVD Reduced Data (Covertype)) - E10 B128: 100%|██████████| 10/10 [00:21<00:00,  2.19s/it]\n",
      "NN Evaluation (EVD Reduced Data (Covertype)): 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVD Reduced Data (Covertype) - Features: 37, Accuracy: 0.8262, Training Time: 21.92s, Inference Time: 0.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if X_wine_train is not None:\n",
    "    print(f\"\\nWine Original Features: {X_wine_train.shape[1]}\")\n",
    "    V_wine_svd = get_svd_transform_matrix(X_wine_train, 0.95, use_linalg_svd=False)\n",
    "    eigvecs_wine_evd = get_evd_transform_matrix(X_wine_train, 0.95)\n",
    "    \n",
    "    X_wine_train_svd, X_wine_test_svd = (X_wine_train @ V_wine_svd, X_wine_test @ V_wine_svd) if V_wine_svd is not None else (None, None)\n",
    "    X_wine_train_evd, X_wine_test_evd = (X_wine_train @ eigvecs_wine_evd, X_wine_test @ eigvecs_wine_evd) if eigvecs_wine_evd is not None else (None, None)\n",
    "    if X_wine_train_svd is not None: print(f\"Wine SVD Reduced Features: {X_wine_train_svd.shape[1]}\")\n",
    "    if X_wine_train_evd is not None: print(f\"Wine EVD Reduced Features: {X_wine_train_evd.shape[1]}\")\n",
    "\n",
    "    print(\"\\nKNN Results on Wine Dataset:\")\n",
    "    train_knn(X_wine_train, X_wine_test, y_wine_train, y_wine_test, \"Original Data (Wine)\")\n",
    "    train_knn(X_wine_train_svd, X_wine_test_svd, y_wine_train, y_wine_test, \"SVD Reduced Data (Wine)\")\n",
    "    train_knn(X_wine_train_evd, X_wine_test_evd, y_wine_train, y_wine_test, \"EVD Reduced Data (Wine)\")\n",
    "\n",
    "for ds in datasets_for_nn:\n",
    "    name = ds[\"name\"]\n",
    "    X_train, X_test, y_train, y_test = ds[\"X_train\"], ds[\"X_test\"], ds[\"y_train\"], ds[\"y_test\"]\n",
    "    output_dim = ds[\"output_dim\"]\n",
    "    use_linalg = ds.get(\"use_linalg_svd\", True)\n",
    "\n",
    "    print(f\"\\n{name} Original Features: {X_train.shape[1]}\")\n",
    "    \n",
    "    V_svd, eigvecs_evd = None, None # Initialize\n",
    "    if X_train.shape[0] > 0 and X_train.shape[1] > 0 : # Ensure data is not empty for SVD/EVD\n",
    "        V_svd = get_svd_transform_matrix(X_train, 0.85, use_linalg_svd=use_linalg)\n",
    "        eigvecs_evd = get_evd_transform_matrix(X_train, 0.85)\n",
    "    \n",
    "        if name == \"MNIST\": # Store MNIST transformation matrices\n",
    "            mnist_components[\"V_svd_transform\"] = V_svd\n",
    "            mnist_components[\"eigvecs_evd_transform\"] = eigvecs_evd\n",
    "    else:\n",
    "        print(f\"Skipping SVD/EVD for {name} due to empty or zero-feature training data.\")\n",
    "\n",
    "\n",
    "    X_train_svd, X_test_svd = (X_train @ V_svd, X_test @ V_svd) if V_svd is not None and X_test is not None else (None, None)\n",
    "    X_train_evd, X_test_evd = (X_train @ eigvecs_evd, X_test @ eigvecs_evd) if eigvecs_evd is not None and X_test is not None else (None, None)\n",
    "    \n",
    "    if X_train_svd is not None: print(f\"{name} SVD Reduced Features: {X_train_svd.shape[1]}\")\n",
    "    if X_train_evd is not None: print(f\"{name} EVD Reduced Features: {X_train_evd.shape[1]}\")\n",
    "        \n",
    "    print(f\"\\nNeural Network Results on {name} Dataset:\")\n",
    "    model_orig, acc_orig = train_neural_network(X_train, X_test, y_train, y_test, f\"Original Data ({name})\", output_dim)\n",
    "    model_svd, acc_svd = train_neural_network(X_train_svd, X_test_svd, y_train, y_test, f\"SVD Reduced Data ({name})\", output_dim)\n",
    "    model_evd, acc_evd = train_neural_network(X_train_evd, X_test_evd, y_train, y_test, f\"EVD Reduced Data ({name})\", output_dim)\n",
    "\n",
    "    if name == \"MNIST\": # Store trained MNIST models\n",
    "        mnist_components[\"model_orig\"] = model_orig\n",
    "        mnist_components[\"model_svd\"] = model_svd\n",
    "        mnist_components[\"model_evd\"] = model_evd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying MNIST Predictions...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Show MNIST Predictions Plot ---\n",
    "if mnist_components[\"X_test_scaled\"] is not None and mnist_components[\"y_test_true\"] is not None:\n",
    "    show_mnist_predictions(\n",
    "        mnist_components[\"X_test_scaled\"],\n",
    "        mnist_components[\"y_test_true\"],\n",
    "        mnist_components[\"model_orig\"],\n",
    "        mnist_components[\"model_svd\"],\n",
    "        mnist_components[\"model_evd\"],\n",
    "        mnist_components[\"V_svd_transform\"],\n",
    "        mnist_components[\"eigvecs_evd_transform\"]\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nSkipping MNIST prediction visualization as MNIST data was not loaded/processed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ================================================================\n",
    "# 1)  ---  CORE LINEAR-ALGEBRA HELPERS  ---------------------------\n",
    "# ================================================================\n",
    "def power_iteration_sym(A: np.ndarray,\n",
    "                        num_iters: int = 1000,\n",
    "                        tol: float = 1e-6) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Return dominant eigenvalue/vector of *symmetric* A via power-iteration.\"\"\"\n",
    "    n = A.shape[0]\n",
    "    v = np.random.randn(n)\n",
    "    v /= np.linalg.norm(v)\n",
    "    last_val = 0.0\n",
    "    for _ in range(num_iters):\n",
    "        w = A @ v\n",
    "        lam = np.dot(v, w)\n",
    "        v = w / np.linalg.norm(w)\n",
    "        if abs(lam - last_val) < tol:\n",
    "            break\n",
    "        last_val = lam\n",
    "    return lam, v\n",
    "\n",
    "\n",
    "def quick_evd_linalg(C: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Top-k eigenvalues/vectors using `np.linalg.eigh` (C must be symmetric).\"\"\"\n",
    "    eigvals, eigvecs = np.linalg.eigh(C)\n",
    "    idx = np.argsort(eigvals)[::-1][:k]\n",
    "    return eigvals[idx], eigvecs[:, idx]\n",
    "\n",
    "\n",
    "def quick_svd_linalg(X: np.ndarray, k: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Top-k SVD via `np.linalg.svd` (economy).\"\"\"\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    return U[:, :k], S[:k], Vt[:k, :]\n",
    "def svd_from_scratch_eighLinalg(X):\n",
    "    \"\"\"\n",
    "    Singular Value Decomposition from scratch using numpy.\n",
    "    \"\"\"\n",
    "    # Calculate X^T * X\n",
    "    XTX = X.T @ X\n",
    "\n",
    "    # Eigen decomposition of X^T * X to get V\n",
    "    eigenvalues_v, eigenvectors_v = np.linalg.eigh(XTX)\n",
    "    \n",
    "    # Sort them\n",
    "    sorted_indices_v = np.argsort(eigenvalues_v)[::-1]\n",
    "    singular_values_sq = eigenvalues_v[sorted_indices_v]\n",
    "    V = eigenvectors_v[:, sorted_indices_v]\n",
    "\n",
    "    # Calculate singular values\n",
    "    singular_values = np.sqrt(singular_values_sq)\n",
    "    \n",
    "    # Create Sigma matrix\n",
    "    Sigma = np.diag(singular_values)\n",
    "\n",
    "    # Calculate U\n",
    "    # U = A * V * Sigma_inv\n",
    "    # To avoid division by zero for small singular values, we compute U directly\n",
    "    U = []\n",
    "    for i in range(len(singular_values)):\n",
    "        if singular_values[i] > 1e-10: # A small threshold to handle floating point inaccuracies\n",
    "            u_i = (X @ V[:, i]) / singular_values[i]\n",
    "            U.append(u_i)\n",
    "    \n",
    "    U = np.array(U).T\n",
    "\n",
    "    return U, singular_values, V.T\n",
    "\n",
    "# ================================================================\n",
    "# 2)  ---  HIGH-LEVEL REDUCTION FUNCTIONS  ------------------------\n",
    "# ================================================================\n",
    "def evd_reduce(X: np.ndarray,\n",
    "               k: int,\n",
    "               *,\n",
    "               center: bool = True,\n",
    "               use_linalg: bool = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reduce X (n_samples × n_features) to k dimensions via EVD/PCA.\n",
    "    Returns (X_reduced, eigvecs, eigvals).\n",
    "    \"\"\"\n",
    "    Xc = X - X.mean(axis=0) if center else X.copy()\n",
    "    C = (Xc.T @ Xc) / (Xc.shape[0] - 1)  # covariance\n",
    "    if use_linalg:\n",
    "        eigvals, eigvecs = quick_evd_linalg(C, k)\n",
    "    else:\n",
    "        # fall back to power-iteration deflation\n",
    "        eigvals = np.zeros(k)\n",
    "        eigvecs = np.zeros((C.shape[0], k))\n",
    "        C_work = C.copy()\n",
    "        for i in range(k):\n",
    "            lam, v = power_iteration_sym(C_work)\n",
    "            eigvals[i] = lam\n",
    "            eigvecs[:, i] = v\n",
    "            C_work -= lam * np.outer(v, v)\n",
    "    X_reduced = X @ eigvecs\n",
    "    return X_reduced, eigvecs, eigvals\n",
    "\n",
    "\n",
    "def svd_reduce(X: np.ndarray,\n",
    "               k: int,\n",
    "               *,\n",
    "               use_linalg: bool = True) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reduce X to k dimensions via (truncated) SVD.\n",
    "    Returns (X_reduced, U_k, S_k, Vt_k).\n",
    "    \"\"\"\n",
    "    if use_linalg:\n",
    "        U, S, Vt = quick_svd_linalg(X, k)\n",
    "    else:\n",
    "        # simple power-iteration SVD (costly for large k)  – demo only\n",
    "        from copy import deepcopy\n",
    "        A = deepcopy(X).astype(float)\n",
    "        m, n = A.shape\n",
    "        U = np.zeros((m, k))\n",
    "        Vt = np.zeros((k, n))\n",
    "        S = np.zeros(k)\n",
    "        for i in range(k):\n",
    "            # Right singular vector via power-iteration on AᵀA\n",
    "            _, v = power_iteration_sym(A.T @ A)\n",
    "            Av = A @ v\n",
    "            sigma = np.linalg.norm(Av)\n",
    "            u = Av / sigma\n",
    "            U[:, i] = u\n",
    "            Vt[i, :] = v\n",
    "            S[i] = sigma\n",
    "            A -= sigma * np.outer(u, v)\n",
    "    X_reduced = U * S  # low-dim coords\n",
    "    return X_reduced, U, S, Vt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
